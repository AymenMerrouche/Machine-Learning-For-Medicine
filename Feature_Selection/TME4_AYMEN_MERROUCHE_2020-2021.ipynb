{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Medicine\n",
    "# Feature Selection\n",
    "> * **Merrouche Aymen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import medical data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast cancer data set : \n",
    "> Describes wheather a breast mas is malignant or not based cell nuclei characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "breast_cancer = pd.read_csv(\"data/Breast.txt\",sep=\" \")\n",
    "breast_cancer_y = breast_cancer.values[:,30] # Classes\n",
    "breast_cancer_X = breast_cancer.values[:,0:29] # Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.82821197, -0.35332152,  1.68447255, ..., -0.14661996,\n",
       "         1.08612862, -0.24367526],\n",
       "       [ 1.5784992 ,  0.45578591,  1.56512598, ...,  0.85422232,\n",
       "         1.95328166,  1.15124203],\n",
       "       [-0.76823332,  0.25350905, -0.59216612, ...,  1.98783917,\n",
       "         2.17387323,  6.04072615],\n",
       "       ...,\n",
       "       [ 0.70166686,  2.04377549,  0.67208442, ...,  0.32647934,\n",
       "         0.41370467, -1.10357792],\n",
       "       [ 1.83672491,  2.33440316,  1.98078127, ...,  3.1947936 ,\n",
       "         2.28797231,  1.9173959 ],\n",
       "       [-1.80681144,  1.22071793, -1.81279344, ..., -1.30468267,\n",
       "        -1.7435287 , -0.04809589]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
       "        1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "       -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "       -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "        1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,\n",
       "        1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "       -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,\n",
       "        1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "        1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "       -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1., -1., -1., -1., -1., -1.,  1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples : 568\n",
      "Dimension of the problem : 29\n",
      "Number of features : 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples :\", breast_cancer_X.shape[0])\n",
    "print(\"Dimension of the problem :\", breast_cancer_X.shape[1])\n",
    "print(\"Number of features :\", np.unique(breast_cancer_y).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Golub et al. 1999 dataset :\n",
    "> Add description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "golub_X = pd.read_csv('data/Golub_X',sep=' ') # Observations\n",
    "golub_y = pd.read_csv('data/Golub_y',sep=' ') # Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples : 71\n",
      "Dimension of the problem : 3562\n",
      "Number of features : 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples :\", golub_X.shape[0])\n",
    "print(\"Dimension of the problem :\", golub_X.shape[1])\n",
    "print(\"Number of features :\", np.unique(golub_y).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_data = {\"breast\" : (pd.DataFrame(breast_cancer_X), breast_cancer_y), \"golub\" : (golub_X, golub_y.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# classifiers to test\n",
    "classifiers = {\"dt\" : DecisionTreeClassifier, \"svm\": SVC, \"gb\" : GradientBoostingClassifier}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Feature Selection by Low Variance Feature Deletion :\n",
    "> In this simple heaursitc approach, we delete features (variables) which have a variance that is lower than a threshold (we expect that variables with a low variance doesn't encompass discriminative information). We test this method on our two medical datasets for different values of the threshold. Furthermore, we compare the results of the different values by feedinf the reduced data matrix to three different classifiers : SVM classifier, Gradient boosting classifierand a decision tree classifier :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To select what threshold to use, we display the varaince of each feature in our two medical datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- breast ----------\n",
      "0     0.999641\n",
      "1     0.994182\n",
      "2     0.998919\n",
      "3     1.000055\n",
      "4     0.997425\n",
      "5     0.982749\n",
      "6     0.989351\n",
      "7     0.990453\n",
      "8     0.993091\n",
      "9     0.992789\n",
      "10    0.990831\n",
      "11    1.001200\n",
      "12    0.987608\n",
      "13    0.990850\n",
      "14    1.001683\n",
      "15    0.998705\n",
      "16    1.000839\n",
      "17    1.000994\n",
      "18    0.999436\n",
      "19    1.000313\n",
      "20    0.995486\n",
      "21    0.998505\n",
      "22    0.992405\n",
      "23    0.994700\n",
      "24    0.998748\n",
      "25    0.989688\n",
      "26    0.993915\n",
      "27    0.992466\n",
      "28    0.988420\n",
      "dtype: float64\n",
      "-------- golub ----------\n",
      "0.708070978820836    0.026607\n",
      "0.928074245939675    0.041344\n",
      "0.553591160220995    0.039379\n",
      "0.449211908931699    0.043680\n",
      "0.36376604850214     0.044423\n",
      "                       ...   \n",
      "0.268886043533931    0.038709\n",
      "0.161897295178361    0.022331\n",
      "0.322953736654804    0.040869\n",
      "0.754658385093168    0.019602\n",
      "0.57089552238806     0.022804\n",
      "Length: 3562, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for data in medical_data :\n",
    "    print(\"--------\",data,\"----------\")\n",
    "    print(medical_data[data][0].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\"breast\" : [0, 0.6, 1], \"golub\" : [0, 0.05, 0.04]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t --------- threshold =  0 ---------\n",
      "\t Reduced Dimension :  29\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.9042553191489362\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.973404255319149\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.9627659574468085\n",
      "\t --------- threshold =  0.6 ---------\n",
      "\t Reduced Dimension :  28\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.9148936170212766\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.973404255319149\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.9574468085106383\n",
      "\t --------- threshold =  1 ---------\n",
      "\t Reduced Dimension :  13\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.898936170212766\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.9574468085106383\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.9468085106382979\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t --------- threshold =  0 ---------\n",
      "\t Reduced Dimension :  3562\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.875\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.875\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.8333333333333334\n",
      "\t --------- threshold =  0.05 ---------\n",
      "\t Reduced Dimension :  504\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.8333333333333334\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.9166666666666666\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.7916666666666666\n",
      "\t --------- threshold =  0.04 ---------\n",
      "\t Reduced Dimension :  1314\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.8333333333333334\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.875\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "for data in medical_data:\n",
    "    print(\"--------\",data,\"----------\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(medical_data[data][0], medical_data[data][1], test_size=0.33, random_state=42)\n",
    "    print(\" Original Dimension : \",X_train.shape[1])\n",
    "    for threshold in thresholds[data] :\n",
    "        print(\"\\t --------- threshold = \",threshold,\"---------\")\n",
    "        sel = VarianceThreshold(threshold=threshold)\n",
    "        sel.fit(X_train)\n",
    "        X_train_t = sel.transform(X_train)\n",
    "        X_test_t = sel.transform(X_test)\n",
    "        print(\"\\t Reduced Dimension : \",X_train_t.shape[1])\n",
    "        for classifier in classifiers:\n",
    "            print(\"\\t\\t --------\",classifier,\"----------\")\n",
    "            clf = classifiers[classifier]().fit(X_train_t, y_train.ravel())\n",
    "            print(\"\\t\\t score after reduction : \",clf.score(X_test_t, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Univariate feature selection with statistical tests :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> we test the effectiveness of this method by feeding the reduced data matrix to three different classifiers : SVM classifier, Gradient boosting classifierand a decision tree classifier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  24\n",
      "\t\t -------- dt ----------\n",
      "\t\t score with no reduction :  0.925531914893617\n",
      "\t\t score after reduction :  0.9202127659574468\n",
      "\t\t -------- svm ----------\n",
      "\t\t score with no reduction :  0.973404255319149\n",
      "\t\t score after reduction :  0.9787234042553191\n",
      "\t\t -------- gb ----------\n",
      "\t\t score with no reduction :  0.9521276595744681\n",
      "\t\t score after reduction :  0.973404255319149\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  94\n",
      "\t\t -------- dt ----------\n",
      "\t\t score with no reduction :  0.9166666666666666\n",
      "\t\t score after reduction :  0.875\n",
      "\t\t -------- svm ----------\n",
      "\t\t score with no reduction :  0.875\n",
      "\t\t score after reduction :  0.9583333333333334\n",
      "\t\t -------- gb ----------\n",
      "\t\t score with no reduction :  0.8333333333333334\n",
      "\t\t score after reduction :  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFdr, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "for data in medical_data:\n",
    "    print(\"--------\",data,\"----------\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(medical_data[data][0], medical_data[data][1], test_size=0.33, random_state=42)\n",
    "    print(\" Original Dimension : \",X_train.shape[1])\n",
    "    sel = SelectFdr(alpha=0.01)\n",
    "    sel.fit(X_train, y_train)\n",
    "    X_train_t = sel.transform(X_train)\n",
    "    X_test_t = sel.transform(X_test)\n",
    "    print(\"\\t Reduced Dimension : \",X_train_t.shape[1])\n",
    "    for classifier in classifiers:\n",
    "        print(\"\\t\\t --------\",classifier,\"----------\")\n",
    "        print(\"\\t\\t score with no reduction : \",classifiers[classifier]().fit(X_train, y_train.ravel()).score(X_test, y_test))\n",
    "        clf = classifiers[classifier]().fit(X_train_t, y_train.ravel())\n",
    "        print(\"\\t\\t score after reduction : \",clf.score(X_test_t, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - L1 based feature selection :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - 1 - Logistic regression penalized by the L1 penalty term :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ alpha =  0.1\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  5\n",
      "\t\t Accuracy score :  0.6914601676351175\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  0\n",
      "\t\t Accuracy score :  -0.005100347065036814\n",
      "++ alpha =  0.01\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  14\n",
      "\t\t Accuracy score :  0.702081907541241\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  27\n",
      "\t\t Accuracy score :  0.7430387022168904\n",
      "++ alpha =  0.03\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  11\n",
      "\t\t Accuracy score :  0.7066900748272553\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  9\n",
      "\t\t Accuracy score :  0.67890243525036\n",
      "++ alpha =  0.05\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  9\n",
      "\t\t Accuracy score :  0.7062767221843955\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  7\n",
      "\t\t Accuracy score :  0.4499548134666942\n",
      "++ alpha =  0.001\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  24\n",
      "\t\t Accuracy score :  0.7577885709627682\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  46\n",
      "\t\t Accuracy score :  0.7740261917369551\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "for alpha in [0.1, 0.01, 0.03, 0.05, 0.001]:\n",
    "    print(\"++ alpha = \", alpha)\n",
    "    lr = linear_model.Lasso(alpha)\n",
    "    print(\"---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\")\n",
    "    for data in medical_data:\n",
    "        print(\"--------\",data,\"----------\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(medical_data[data][0], medical_data[data][1], test_size=0.33, random_state=42)\n",
    "        print(\" Original Dimension : \",X_train.shape[1])\n",
    "\n",
    "        lr.fit(X_train, y_train)\n",
    "        model = SelectFromModel(lr, prefit=True)\n",
    "        X_train_t = model.transform(X_train)\n",
    "        X_test_t = model.transform(X_test)\n",
    "        print(\"\\t Reduced Dimension : \",X_train_t.shape[1])\n",
    "        print(\"\\t\\t Accuracy score : \",lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - 2 - support vector machine penalized by the L1 penalty term :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ C =  0.1\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  14\n",
      "\t\t Accuracy score :  0.973404255319149\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  4\n",
      "\t\t Accuracy score :  0.8333333333333334\n",
      "++ C =  0.3\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  15\n",
      "\t\t Accuracy score :  0.973404255319149\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  17\n",
      "\t\t Accuracy score :  0.9166666666666666\n",
      "++ C =  0.5\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  18\n",
      "\t\t Accuracy score :  0.973404255319149\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  22\n",
      "\t\t Accuracy score :  0.9166666666666666\n",
      "++ C =  0.01\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  5\n",
      "\t\t Accuracy score :  0.9574468085106383\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  0\n",
      "\t\t Accuracy score :  0.625\n",
      "++ C =  0.001\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  0\n",
      "\t\t Accuracy score :  0.3829787234042553\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  0\n",
      "\t\t Accuracy score :  0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "for C in [0.1, 0.3 ,0.5 , 0.01, 0.001] :\n",
    "    print(\"++ C = \", C)\n",
    "    lsvc = LinearSVC(C=C, penalty=\"l1\", dual=False)\n",
    "    print(\"---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\")\n",
    "\n",
    "    for data in medical_data:\n",
    "        print(\"--------\",data,\"----------\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(medical_data[data][0], medical_data[data][1], test_size=0.33, random_state=42)\n",
    "        print(\" Original Dimension : \",X_train.shape[1])\n",
    "\n",
    "        lsvc.fit(X_train, y_train)\n",
    "        model = SelectFromModel(lsvc, prefit=True)\n",
    "        X_train_t = model.transform(X_train)\n",
    "        X_test_t = model.transform(X_test)\n",
    "        print(\"\\t Reduced Dimension : \",X_train_t.shape[1])\n",
    "        print(\"\\t\\t Accuracy score : \",lsvc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - 1 - Elastic Net, a compromise between the L1 and L2 penalty terms :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ alpha =  0.1\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  8\n",
      "\t\t Accuracy score :  0.6971187769445253\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  2\n",
      "\t\t Accuracy score :  0.11559885941836068\n",
      "++ alpha =  0.01\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  12\n",
      "\t\t Accuracy score :  0.7046129669750714\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  39\n",
      "\t\t Accuracy score :  0.7494702118910411\n",
      "++ alpha =  0.03\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  9\n",
      "\t\t Accuracy score :  0.7054564989723608\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  18\n",
      "\t\t Accuracy score :  0.7311857493837736\n",
      "++ alpha =  0.05\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  8\n",
      "\t\t Accuracy score :  0.7052644168506177\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  12\n",
      "\t\t Accuracy score :  0.5977277751643426\n",
      "++ alpha =  0.001\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  7\n",
      "\t\t Accuracy score :  0.7581289306312518\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  51\n",
      "\t\t Accuracy score :  0.7531743294441532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "for alpha in [0.1, 0.01, 0.03, 0.05, 0.001]:\n",
    "    print(\"++ alpha = \", alpha)\n",
    "    eln = ElasticNet(alpha, l1_ratio=0.7)\n",
    "\n",
    "    for data in medical_data:\n",
    "        print(\"--------\",data,\"----------\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(medical_data[data][0], medical_data[data][1], test_size=0.33, random_state=42)\n",
    "        print(\" Original Dimension : \",X_train.shape[1])\n",
    "\n",
    "        eln.fit(X_train, y_train)\n",
    "        model = SelectFromModel(eln, prefit=True)\n",
    "        X_train_t = model.transform(X_train)\n",
    "        X_test_t = model.transform(X_test)\n",
    "        print(\"\\t Reduced Dimension : \",X_train_t.shape[1])\n",
    "        print(\"\\t\\t Accuracy score : \",eln.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Comparing the results :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Golub Dataset :**\n",
    "> * The best classifier for the Golub dataset is the linear support vector classifier for $C \\in \\{0.3, 0.5\\}$, the number of selected variable for this classifer was 17/3562. The score on the test set was $0.916$. Followed by the logistic regression classifier for $\\alpha = 0.001$, the number of selected variable for this classifer was 46/3562. The score on the test set was $0.774$. Finally, the less performant classifier was the ElasticNet classifier for $\\alpha = 0.001$, the number of selected variable for this classifer was 51/3562. The score on the test set was $0.753$.\n",
    "\n",
    "> **Breast dataset :**\n",
    "> * The best classifier for the Breast dataset is the linear support vector classifier for $C = 0.01$, the number of selected variable for this classifer was 5/29. The score on the test set was $0.957$. Followed by the ElasticNet classifier for $\\alpha = 0.001$, the number of selected variable for this classifer was 7/29. The score on the test set was $0.758$  Finally, the less performant classifier was the logistic regression classifier for $\\alpha = 0.001$, the number of selected variable for this classifer was 24/29. The score on the test set was $0.757$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
