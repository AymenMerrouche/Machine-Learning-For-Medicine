{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Medicine\n",
    "# Practical Session 5 : Logistic Regression & K-fold cross validation\n",
    "> * **Merrouche Aymen**\n",
    "* Student number : **3802993**\n",
    "* Prepared master's degree : **M2A**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import medical data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast cancer data set : \n",
    "> Describes wheather a breast mas is malignant or not based cell nuclei characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/BreastDiagnostic.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aaca4939a01b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbreast_cancer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"BreastDiagnostic.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;31m# default to avoid a ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/BreastDiagnostic.txt'"
     ]
    }
   ],
   "source": [
    "# import the data\n",
    "data_path = './data/'\n",
    "breast_cancer = pd.read_table(data_path+\"BreastDiagnostic.txt\",sep=\",\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_X = breast_cancer.drop([0, 1], axis=1)\n",
    "breast_cancer_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_y = breast_cancer[1]\n",
    "breast_cancer_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples : 568\n",
      "Dimension of the problem : 29\n",
      "Number of features : 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples :\", breast_cancer_X.shape[0])\n",
    "print(\"Dimension of the problem :\", breast_cancer_X.shape[1])\n",
    "print(\"Number of features :\", np.unique(breast_cancer_y).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Golub et al. 1999 dataset :\n",
    "> Add description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "golub_X = pd.read_csv('data/Golub_X',sep=' ') # Observations\n",
    "golub_y = pd.read_csv('data/Golub_y',sep=' ') # Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples : 71\n",
      "Dimension of the problem : 3562\n",
      "Number of features : 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples :\", golub_X.shape[0])\n",
    "print(\"Dimension of the problem :\", golub_X.shape[1])\n",
    "print(\"Number of features :\", np.unique(golub_y).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_data = {\"breast\" : (pd.DataFrame(breast_cancer_X), breast_cancer_y), \"golub\" : (golub_X, golub_y.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# classifiers to test\n",
    "classifiers = {\"dt\" : DecisionTreeClassifier, \"svm\": SVC, \"gb\" : GradientBoostingClassifier}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Feature Selection by Low Variance Feature Deletion :\n",
    "> In this simple heaursitc approach, we delete features (variables) which have a variance that is lower than a threshold (we expect that variables with a low variance doesn't encompass discriminative information). We test this method on our two medical datasets for different values of the threshold. Furthermore, we compare the results of the different values by feedinf the reduced data matrix to three different classifiers : SVM classifier, Gradient boosting classifierand a decision tree classifier :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To select what threshold to use, we display the varaince of each feature in our two medical datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- breast ----------\n",
      "0     0.999641\n",
      "1     0.994182\n",
      "2     0.998919\n",
      "3     1.000055\n",
      "4     0.997425\n",
      "5     0.982749\n",
      "6     0.989351\n",
      "7     0.990453\n",
      "8     0.993091\n",
      "9     0.992789\n",
      "10    0.990831\n",
      "11    1.001200\n",
      "12    0.987608\n",
      "13    0.990850\n",
      "14    1.001683\n",
      "15    0.998705\n",
      "16    1.000839\n",
      "17    1.000994\n",
      "18    0.999436\n",
      "19    1.000313\n",
      "20    0.995486\n",
      "21    0.998505\n",
      "22    0.992405\n",
      "23    0.994700\n",
      "24    0.998748\n",
      "25    0.989688\n",
      "26    0.993915\n",
      "27    0.992466\n",
      "28    0.988420\n",
      "dtype: float64\n",
      "-------- golub ----------\n",
      "0.708070978820836    0.026607\n",
      "0.928074245939675    0.041344\n",
      "0.553591160220995    0.039379\n",
      "0.449211908931699    0.043680\n",
      "0.36376604850214     0.044423\n",
      "                       ...   \n",
      "0.268886043533931    0.038709\n",
      "0.161897295178361    0.022331\n",
      "0.322953736654804    0.040869\n",
      "0.754658385093168    0.019602\n",
      "0.57089552238806     0.022804\n",
      "Length: 3562, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for data in medical_data :\n",
    "    print(\"--------\",data,\"----------\")\n",
    "    print(medical_data[data][0].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\"breast\" : [0, 0.6, 1], \"golub\" : [0, 0.05, 0.04]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t --------- threshold =  0 ---------\n",
      "\t Reduced Dimension :  29\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.9148936170212766\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.973404255319149\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.9627659574468085\n",
      "\t --------- threshold =  0.6 ---------\n",
      "\t Reduced Dimension :  28\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.925531914893617\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.973404255319149\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.9574468085106383\n",
      "\t --------- threshold =  1 ---------\n",
      "\t Reduced Dimension :  13\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.9308510638297872\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.9574468085106383\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.9468085106382979\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t --------- threshold =  0 ---------\n",
      "\t Reduced Dimension :  3562\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.7916666666666666\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.875\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.8333333333333334\n",
      "\t --------- threshold =  0.05 ---------\n",
      "\t Reduced Dimension :  504\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.8333333333333334\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.9166666666666666\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.7916666666666666\n",
      "\t --------- threshold =  0.04 ---------\n",
      "\t Reduced Dimension :  1314\n",
      "\t\t -------- dt ----------\n",
      "\t\t score after reduction :  0.75\n",
      "\t\t -------- svm ----------\n",
      "\t\t score after reduction :  0.875\n",
      "\t\t -------- gb ----------\n",
      "\t\t score after reduction :  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "for data in medical_data:\n",
    "    print(\"--------\",data,\"----------\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(medical_data[data][0], medical_data[data][1], test_size=0.33, random_state=42)\n",
    "    print(\" Original Dimension : \",X_train.shape[1])\n",
    "    for threshold in thresholds[data] :\n",
    "        print(\"\\t --------- threshold = \",threshold,\"---------\")\n",
    "        sel = VarianceThreshold(threshold=threshold)\n",
    "        sel.fit(X_train)\n",
    "        X_train_t = sel.transform(X_train)\n",
    "        X_test_t = sel.transform(X_test)\n",
    "        print(\"\\t Reduced Dimension : \",X_train_t.shape[1])\n",
    "        for classifier in classifiers:\n",
    "            print(\"\\t\\t --------\",classifier,\"----------\")\n",
    "            clf = classifiers[classifier]().fit(X_train_t, y_train.ravel())\n",
    "            print(\"\\t\\t score after reduction : \",clf.score(X_test_t, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Univariate feature selection with statistical tests :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> we test the effectiveness of this method by feeding the reduced data matrix to three different classifiers : SVM classifier, Gradient boosting classifierand a decision tree classifier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  24\n",
      "\t\t -------- dt ----------\n",
      "\t\t score with no reduction :  0.9308510638297872\n",
      "\t\t score after reduction :  0.9148936170212766\n",
      "\t\t -------- svm ----------\n",
      "\t\t score with no reduction :  0.973404255319149\n",
      "\t\t score after reduction :  0.9787234042553191\n",
      "\t\t -------- gb ----------\n",
      "\t\t score with no reduction :  0.9627659574468085\n",
      "\t\t score after reduction :  0.9680851063829787\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  94\n",
      "\t\t -------- dt ----------\n",
      "\t\t score with no reduction :  0.8333333333333334\n",
      "\t\t score after reduction :  0.7916666666666666\n",
      "\t\t -------- svm ----------\n",
      "\t\t score with no reduction :  0.875\n",
      "\t\t score after reduction :  0.9583333333333334\n",
      "\t\t -------- gb ----------\n",
      "\t\t score with no reduction :  0.875\n",
      "\t\t score after reduction :  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFdr, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "for data in medical_data:\n",
    "    print(\"--------\",data,\"----------\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(medical_data[data][0], medical_data[data][1], test_size=0.33, random_state=42)\n",
    "    print(\" Original Dimension : \",X_train.shape[1])\n",
    "    sel = SelectFdr(alpha=0.01)\n",
    "    sel.fit(X_train, y_train)\n",
    "    X_train_t = sel.transform(X_train)\n",
    "    X_test_t = sel.transform(X_test)\n",
    "    print(\"\\t Reduced Dimension : \",X_train_t.shape[1])\n",
    "    for classifier in classifiers:\n",
    "        print(\"\\t\\t --------\",classifier,\"----------\")\n",
    "        print(\"\\t\\t score with no reduction : \",classifiers[classifier]().fit(X_train, y_train.ravel()).score(X_test, y_test))\n",
    "        clf = classifiers[classifier]().fit(X_train_t, y_train.ravel())\n",
    "        print(\"\\t\\t score after reduction : \",clf.score(X_test_t, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - L1 based feature selection :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - 1 - Logistic regression penalized by the L1 penalty term :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ alpha =  0.1\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  5\n",
      "\t\t Accuracy score :  0.6914601676351175\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  0\n",
      "\t\t Accuracy score :  -0.005100347065036814\n",
      "++ alpha =  0.01\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  14\n",
      "\t\t Accuracy score :  0.702081907541241\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  27\n",
      "\t\t Accuracy score :  0.7430387022168904\n",
      "++ alpha =  0.03\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  11\n",
      "\t\t Accuracy score :  0.7066900748272553\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  9\n",
      "\t\t Accuracy score :  0.67890243525036\n",
      "++ alpha =  0.05\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  9\n",
      "\t\t Accuracy score :  0.7062767221843955\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  7\n",
      "\t\t Accuracy score :  0.4499548134666942\n",
      "++ alpha =  0.001\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  24\n",
      "\t\t Accuracy score :  0.7577885709627682\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  46\n",
      "\t\t Accuracy score :  0.7740261917369551\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "for alpha in [0.1, 0.01, 0.03, 0.05, 0.001]:\n",
    "    print(\"++ alpha = \", alpha)\n",
    "    lr = linear_model.Lasso(alpha)\n",
    "    print(\"---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\")\n",
    "    for data in medical_data:\n",
    "        print(\"--------\",data,\"----------\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(medical_data[data][0], medical_data[data][1], test_size=0.33, random_state=42)\n",
    "        print(\" Original Dimension : \",X_train.shape[1])\n",
    "\n",
    "        lr.fit(X_train, y_train)\n",
    "        model = SelectFromModel(lr, prefit=True)\n",
    "        X_train_t = model.transform(X_train)\n",
    "        X_test_t = model.transform(X_test)\n",
    "        print(\"\\t Reduced Dimension : \",X_train_t.shape[1])\n",
    "        print(\"\\t\\t Accuracy score : \",lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - 2 - support vector machinepenalized by theL1penalty term :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ C =  0.1\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  14\n",
      "\t\t Accuracy score :  0.973404255319149\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  4\n",
      "\t\t Accuracy score :  0.8333333333333334\n",
      "++ C =  0.3\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  15\n",
      "\t\t Accuracy score :  0.973404255319149\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  17\n",
      "\t\t Accuracy score :  0.9166666666666666\n",
      "++ C =  0.5\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  18\n",
      "\t\t Accuracy score :  0.973404255319149\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  22\n",
      "\t\t Accuracy score :  0.9166666666666666\n",
      "++ C =  0.01\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  5\n",
      "\t\t Accuracy score :  0.9574468085106383\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  0\n",
      "\t\t Accuracy score :  0.625\n",
      "++ C =  0.001\n",
      "---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  0\n",
      "\t\t Accuracy score :  0.3829787234042553\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  0\n",
      "\t\t Accuracy score :  0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "for C in [0.1, 0.3 ,0.5 , 0.01, 0.001] :\n",
    "    print(\"++ C = \", C)\n",
    "    lsvc = LinearSVC(C=C, penalty=\"l1\", dual=False)\n",
    "    print(\"---------------------- Logistic Regression penalized by the L1 penalty term ---------------------\")\n",
    "\n",
    "    for data in medical_data:\n",
    "        print(\"--------\",data,\"----------\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(medical_data[data][0], medical_data[data][1], test_size=0.33, random_state=42)\n",
    "        print(\" Original Dimension : \",X_train.shape[1])\n",
    "\n",
    "        lsvc.fit(X_train, y_train)\n",
    "        model = SelectFromModel(lsvc, prefit=True)\n",
    "        X_train_t = model.transform(X_train)\n",
    "        X_test_t = model.transform(X_test)\n",
    "        print(\"\\t Reduced Dimension : \",X_train_t.shape[1])\n",
    "        print(\"\\t\\t Accuracy score : \",lsvc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - 1 - Elastic Net, a compromise between theL1andL2penalty terms :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ alpha =  0.1\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  8\n",
      "\t\t Accuracy score :  0.6971187769445253\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  2\n",
      "\t\t Accuracy score :  0.11559885941836068\n",
      "++ alpha =  0.01\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  12\n",
      "\t\t Accuracy score :  0.7046129669750714\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  39\n",
      "\t\t Accuracy score :  0.7494702118910411\n",
      "++ alpha =  0.03\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  9\n",
      "\t\t Accuracy score :  0.7054564989723608\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  18\n",
      "\t\t Accuracy score :  0.7311857493837736\n",
      "++ alpha =  0.05\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  8\n",
      "\t\t Accuracy score :  0.7052644168506177\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  12\n",
      "\t\t Accuracy score :  0.5977277751643426\n",
      "++ alpha =  0.001\n",
      "-------- breast ----------\n",
      " Original Dimension :  29\n",
      "\t Reduced Dimension :  7\n",
      "\t\t Accuracy score :  0.7581289306312518\n",
      "-------- golub ----------\n",
      " Original Dimension :  3562\n",
      "\t Reduced Dimension :  51\n",
      "\t\t Accuracy score :  0.7531743294441532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "for alpha in [0.1, 0.01, 0.03, 0.05, 0.001]:\n",
    "    print(\"++ alpha = \", alpha)\n",
    "    eln = ElasticNet(alpha, l1_ratio=0.7)\n",
    "\n",
    "    for data in medical_data:\n",
    "        print(\"--------\",data,\"----------\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(medical_data[data][0], medical_data[data][1], test_size=0.33, random_state=42)\n",
    "        print(\" Original Dimension : \",X_train.shape[1])\n",
    "\n",
    "        eln.fit(X_train, y_train)\n",
    "        model = SelectFromModel(eln, prefit=True)\n",
    "        X_train_t = model.transform(X_train)\n",
    "        X_test_t = model.transform(X_test)\n",
    "        print(\"\\t Reduced Dimension : \",X_train_t.shape[1])\n",
    "        print(\"\\t\\t Accuracy score : \",eln.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Comparing the results :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Golub Dataset :**\n",
    "> * The best classifier for the Golub dataset is the linear support vector classifier for $C \\in \\{0.3, 0.5\\}$, the number of selected variable for this classifer was 17/3562. The score on the test set was $0.916$. Followed by the logistic regression classifier for $\\alpha = 0.001$, the number of selected variable for this classifer was 46/3562. The score on the test set was $0.774$. Finally, the less performant classifier was the ElasticNet classifier for $\\alpha = 0.001$, the number of selected variable for this classifer was 51/3562. The score on the test set was $0.753$.\n",
    "\n",
    "> **Breast dataset :**\n",
    "> * The best classifier for the Breast dataset is the linear support vector classifier for $C = 0.01$, the number of selected variable for this classifer was 5/29. The score on the test set was $0.957$. Followed by the ElasticNet classifier for $\\alpha = 0.001$, the number of selected variable for this classifer was 7/29. The score on the test set was $0.758$  Finally, the less performant classifier was the logistic regression classifier for $\\alpha = 0.001$, the number of selected variable for this classifer was 24/29. The score on the test set was $0.757$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
